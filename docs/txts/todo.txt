  一些想做的
    author:renlu.xu<xurenlu@gmail.com> 
    Last Updated: %%date(%Y-%m-%d)

%!target:html
%!encoding: UTF-8
%!options: --toc --toc-level=4
%!postproc(html): @@ <BR>
%!postproc(xhtml): @@ <BR>
%!postproc(html): {{(.*?)}} <\1>
%!postproc(html): {{ <
%!postproc(html): }} >

+ 给URL 打分  +
    
    URL 的打分可以从以下几个方面着手:
        + 链接数;在Hyer能做到的情况下,更多的是站内链接;不过站内链接仍然反映了该链接是不是“重要";比如像首页,关于我们等页面的链接数一般都比较高;
        + 链接到该页的页面的分数;类似google pagerank,这个好理解;
        + Url 层次;主要是指目录层次;
        + URL 是静态的还是动态的(大多情况下是指有没有带问号)
        + Url 出现参数的个数;指的是像http://a.com/?arg1=val1&arg2=val2;具体实现上,简单地采取第多一个参数就多扣一些分的形式;
        + Url 长度:长度越少,分数越少;长度不包括域名和schema部分;长度和分数不是线性关系;
        

    其中,分数分为两个,一个是第一次发现该链接就可以打出来的,另一个是以后第n次访问该链接时可以修正的,总分数由两者加权来计算;


+ 网页的上下级关系和深度 +

    - 除开一开始指定的种子URL外,每个URL {A}都是在一个网页{B}中被发现的;网页B被称为“上级",网页A被称为“下级";
    - 上级和下级都不是唯一的;种子URL的深度为0,他的下级页深度为1,再下下级深度为2,3,4....上级网页的深度比下级网页的深度小1;如果一个网页深度为N,那么他的上级网页深度为n-1,他的下一级网页深度为n+1;
    - 网页的深度也有很多种,因为每一个网页都可能被多外网页链接,而这些网页的深度也各不相同;
    - 这里的深度,只针对一次抓取而言;因为,互联网是相互交织的一张网,我们不知道哪一个页面才能算是“入口",因此我们取名为"抓取深度";
    - 对于一个站内(比如www.xinhuanet.com域下)的所有网页,我们按其目录层次给定其“目录深度",这个深度,以其URL中去掉schema和域名的部分的斜杠个数来计算;像http://www.sohu.com/dir//index.html这类网址应该事先被规整化,变成http://www.sohu.com/dir/index.html再计算，去掉http://www.sohu.com,剩余的就是/dir/index.html,目录深度就计为2;


+ 网页的重定向 +
    
    - 网页重定向,分为临时重定向和永久重定向。
        - 临时重定向,不计录要转向的目的地址;
        - 永久重定向,将当前URL的地址标记为已经访问和永久转向,将要转向的目标地址入库等待抓取;



+ 字符集的猜解 +

    目前这一版(0.6.10)简单地使用了chardet来猜文档地编码,这个相当地慢;目前可改进的方式有俩:
        - 不需要将文档的全部部分丢给chardet来猜测编码,只需要前n个字节就可以猜,一般来说,前1000字节已经足够;若大部分网页为30K,此改进在这方面能节省29/30的计算资源;
        - 对于单个网站或单个频道,一般来说是会使用同一种编码的:
            - 假设http://news.a.com/a.html 是GBK编码,那http://news.a.com/b.html基本可以定为是GBK的;
            - 假设http://a.com/path1/filea.html是GBK编码的,那么http://a.com/path1/fileb.html也可以认为是GBK的;
            - 假设http://www.a.com/path1.php?id={a}是GBK编码的,那么http://www.a.com/path1.php?id={b}也可以认为是GBK的;

+ 本地DNS缓存 +
    做Profile 发现, Socket->recv和socket->getAddrInfo是比较费时的.前一个目前没有办法优化的,可以先加本地dns缓存,以减少gethostbyname的时间共费;
